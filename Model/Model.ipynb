{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460c8f49-a809-4603-8e72-95b34791faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c97172-1454-45a1-b7c7-db1478614e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../Data Warehousing ETL/Transformed_Data/individuals_cyber_attacks_europe.csv')\n",
    "\n",
    "# Define new classes for quantile-based binning\n",
    "classes = [ 'Low', 'Medium', 'High']\n",
    "\n",
    "# Apply quantile-based binning with pd.qcut\n",
    "df['Anomaly_Class'] = pd.qcut(df['Anomaly_Scores'], q=3, labels=classes)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Anomaly_Scores', 'User_Information', 'Payload_Data', 'Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d484b6f9-cdb5-49ad-ba6d-37fb127819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding categorical columns\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "    label_encoders[column] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c5f92b-a29c-4ec4-8e2f-7a87171ce366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop(columns=['Anomaly_Class'])\n",
    "y = df['Anomaly_Class']\n",
    "\n",
    "# Encode the target labels using LabelEncoder\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)  # y_encoded will be used for training\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c09ab1d-09c6-47f9-9e00-af10b0271a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Attack_Signature', 'Source_IP_Address', 'Destination_Port',\n",
      "       'Packet_Length', 'Destination_IP_Address', 'Source_Port', 'Day',\n",
      "       'Attack_Type', 'Hour_of_Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection using RandomForest to identify important features\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Select top features based on importance\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_10_indices = indices[:10]\n",
    "top_10_features = X.columns[top_10_indices]\n",
    "print(top_10_features)\n",
    "\n",
    "# Use only the top 10 features for model selection\n",
    "X_train_top_10 = X_train[top_10_features]\n",
    "X_test_top_10 = X_test[top_10_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a502849-bcfe-45f1-bba5-d79d6c1610da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers with default parameters\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c730dc98-c08a-4f40-a44e-547452410a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, use_scaling=False):\n",
    "    if use_scaling:\n",
    "        X_test = StandardScaler().fit_transform(X_test)\n",
    "        \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print the evaluation results\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le_target.classes_))  # Use original class names\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Return F1 score for selecting the best model\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b52be1-1480-48bb-a6bb-5fe6a114e8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating RandomForest with default parameters:\n",
      "Accuracy: 0.5325333333333333\n",
      "Precision: 0.6082921086777036\n",
      "Recall: 0.5325333333333333\n",
      "F1 Score: 0.5517506668490825\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.51      0.46      5055\n",
      "         Low       0.99      0.60      0.75      4971\n",
      "      Medium       0.41      0.49      0.45      4974\n",
      "\n",
      "    accuracy                           0.53     15000\n",
      "   macro avg       0.61      0.53      0.55     15000\n",
      "weighted avg       0.61      0.53      0.55     15000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2571   10 2474]\n",
      " [1009 2977  985]\n",
      " [2524   10 2440]]\n",
      "\n",
      "Training and evaluating GradientBoosting with default parameters:\n",
      "Accuracy: 0.5292666666666667\n",
      "Precision: 0.6064931314455911\n",
      "Recall: 0.5292666666666667\n",
      "F1 Score: 0.5487156505917826\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.47      0.44      5055\n",
      "         Low       1.00      0.60      0.75      4971\n",
      "      Medium       0.41      0.52      0.46      4974\n",
      "\n",
      "    accuracy                           0.53     15000\n",
      "   macro avg       0.61      0.53      0.55     15000\n",
      "weighted avg       0.61      0.53      0.55     15000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2384    4 2667]\n",
      " [ 932 2971 1068]\n",
      " [2380   10 2584]]\n",
      "\n",
      "Training and evaluating XGBoost with default parameters:\n",
      "Accuracy: 0.5286666666666666\n",
      "Precision: 0.5974859996004198\n",
      "Recall: 0.5286666666666666\n",
      "F1 Score: 0.5468962070124792\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.49      0.45      5055\n",
      "         Low       0.97      0.60      0.74      4971\n",
      "      Medium       0.41      0.50      0.45      4974\n",
      "\n",
      "    accuracy                           0.53     15000\n",
      "   macro avg       0.60      0.53      0.55     15000\n",
      "weighted avg       0.60      0.53      0.55     15000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2454   55 2546]\n",
      " [ 941 2997 1033]\n",
      " [2445   50 2479]]\n",
      "\n",
      "Best model based on F1 score: RandomForest with F1 score: 0.5517506668490825\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models and store their performance (F1 score)\n",
    "best_f1 = 0\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"\\nTraining and evaluating {name} with default parameters:\")\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train_top_10, y_train)\n",
    "    \n",
    "    # Evaluate the model's performance on the test data\n",
    "    use_scaling = False  # XGBoost and GradientBoosting do not require scaling by default\n",
    "    f1 = evaluate_model(model, X_test_top_10, y_test)\n",
    "    \n",
    "    # Track the best model based on F1 score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\nBest model based on F1 score: {best_model_name} with F1 score: {best_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db33492e-3677-4f8e-b38c-bcde89a8ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids for tuning the best model\n",
    "param_grid = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a7876a-f36c-4f68-913f-deffb8c90ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning hyperparameters for RandomForest...\n",
      "Best parameters for RandomForest: {'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 10}\n",
      "\n",
      "Evaluating RandomForest after hyperparameter tuning:\n",
      "Accuracy: 0.5290666666666667\n",
      "Precision: 0.6078221080923382\n",
      "Recall: 0.5290666666666667\n",
      "F1 Score: 0.5475795407339454\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.43      0.42      5055\n",
      "         Low       1.00      0.60      0.75      4971\n",
      "      Medium       0.41      0.56      0.47      4974\n",
      "\n",
      "    accuracy                           0.53     15000\n",
      "   macro avg       0.61      0.53      0.55     15000\n",
      "weighted avg       0.61      0.53      0.55     15000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2165    0 2890]\n",
      " [ 840 2971 1160]\n",
      " [2174    0 2800]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Function to perform randomized search\n",
    "def run_random_search(model, params, X_train, y_train):\n",
    "    search = RandomizedSearchCV(model, param_distributions=params, n_iter=10, cv=3, random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "# Perform hyperparameter tuning only for the best model\n",
    "if best_model_name is not None:\n",
    "    print(f\"\\nTuning hyperparameters for {best_model_name}...\")\n",
    "    best_model_tuned, best_params = run_random_search(classifiers[best_model_name], param_grid[best_model_name], X_train_top_10, y_train)\n",
    "    \n",
    "    print(f\"Best parameters for {best_model_name}: {best_params}\")\n",
    "    \n",
    "    # Evaluate the tuned model\n",
    "    print(f\"\\nEvaluating {best_model_name} after hyperparameter tuning:\")\n",
    "    evaluate_model(best_model_tuned, X_test_top_10, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34755a24-3f28-42b7-bfe1-05f312760e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "if best_model_tuned:\n",
    "    joblib.dump(best_model_tuned, 'best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28376e88-a317-4585-b658-e43c89f7a125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top_10_features.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming top_10_features is a list or array of feature names\n",
    "top_10_features = X.columns[top_10_indices].tolist()\n",
    "\n",
    "# Save top features to a file\n",
    "joblib.dump(top_10_features, 'top_10_features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
